{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yourdailybread1/fork-tvdatafeed/blob/main/BULK_DATA_UPDATER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQk3db7uqcT-",
        "outputId": "2a7548e4-054c-469e-ba02-72ec50c9631e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/yourdailybread1/fork-tvdatafeed.git@main\n",
            "  Cloning https://github.com/yourdailybread1/fork-tvdatafeed.git (to revision main) to /tmp/pip-req-build-i10pnfan\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/yourdailybread1/fork-tvdatafeed.git /tmp/pip-req-build-i10pnfan\n",
            "  Resolved https://github.com/yourdailybread1/fork-tvdatafeed.git to commit 1bca18686500b3131837a2c724d2e75fb1580adb\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from tvdatafeed==2.0.0) (75.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from tvdatafeed==2.0.0) (2.2.2)\n",
            "Requirement already satisfied: websocket-client in /usr/local/lib/python3.12/dist-packages (from tvdatafeed==2.0.0) (1.8.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from tvdatafeed==2.0.0) (2.32.4)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas->tvdatafeed==2.0.0) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->tvdatafeed==2.0.0) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->tvdatafeed==2.0.0) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->tvdatafeed==2.0.0) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->tvdatafeed==2.0.0) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->tvdatafeed==2.0.0) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->tvdatafeed==2.0.0) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->tvdatafeed==2.0.0) (2025.8.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->tvdatafeed==2.0.0) (1.17.0)\n",
            "Building wheels for collected packages: tvdatafeed\n",
            "  Building wheel for tvdatafeed (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tvdatafeed: filename=tvdatafeed-2.0.0-py3-none-any.whl size=7288 sha256=a0d0c53ec37ca2d8f539b2e34fc1d26204a5b7d7504c8f4008c675f3c0b0f812\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3ofdg9ab/wheels/c8/5d/91/dd1909bc39ac07513cf02825f93c59955c91cbcb30af80136b\n",
            "Successfully built tvdatafeed\n",
            "Installing collected packages: tvdatafeed\n",
            "Successfully installed tvdatafeed-2.0.0\n",
            "Collecting schedule\n",
            "  Downloading schedule-1.2.2-py3-none-any.whl.metadata (3.8 kB)\n",
            "Downloading schedule-1.2.2-py3-none-any.whl (12 kB)\n",
            "Installing collected packages: schedule\n",
            "Successfully installed schedule-1.2.2\n"
          ]
        }
      ],
      "source": [
        "# Run in Terminal to instal on system\n",
        "!pip install git+https://github.com/yourdailybread1/fork-tvdatafeed.git@main\n",
        "!pip install schedule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RDavugu7q2mF",
        "outputId": "9b672d03-ef61-43a0-aa66-f19d37da9e96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tvDatafeed.main:error while signin\n",
            "WARNING:tvDatafeed.main:you are using nologin method, data you access may be limited\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data for ES saved to temp_es_2h_data.csv\n",
            "Script started at 2025-09-06 14:49:02.761176\n",
            "Datetime column converted to EST.\n",
            "Master file /content/drive/My Drive/Data/ES Price Data/ES_2H_Price_Data.csv updated successfully.\n",
            "datetime    2025-09-05 16:00:00\n",
            "symbol            CME_MINI:ES1!\n",
            "open                    6490.75\n",
            "high                     6491.5\n",
            "low                     6485.25\n",
            "close                   6488.75\n",
            "volume                  45036.0\n",
            "Name: 4999, dtype: object\n",
            "Temporary file temp_es_2h_data.csv removed.\n",
            "Script completed at 2025-09-06 14:49:04.253536\n"
          ]
        }
      ],
      "source": [
        "### ES 2H TIMEFRAME ###\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import pytz  # Required for timezone conversion\n",
        "\n",
        "# Configuration\n",
        "TWOH_TEMP_FILE = \"temp_es_2h_data.csv\"  # Name of the local file containing daily data\n",
        "TWOH_MASTER_FILE = \"/content/drive/My Drive/Data/ES Price Data/ES_2H_Price_Data.csv\"  # Path to the master file in Google Drive\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Function to download temp file from TradingView\n",
        "def download_futures_data(username: str, password: str, symbol: str, exchange: str, interval: Interval, n_bars: int,\n",
        "                          filename: str):\n",
        "    # Initialize the TvDatafeed object with the given username and password\n",
        "    tv = TvDatafeed(username, password)\n",
        "\n",
        "    # Get the historical data for the specified futures contract\n",
        "    futures_data = tv.get_hist(symbol=symbol, exchange=exchange, interval=interval, n_bars=n_bars, fut_contract=1)\n",
        "\n",
        "    # Save the data to a CSV file\n",
        "    futures_data.to_csv(filename)\n",
        "    print(f\"Data for {symbol} saved to {filename}\")\n",
        "\n",
        "# Function to convert datetime to New York EST\n",
        "def convert_to_est(dataframe):\n",
        "    try:\n",
        "        # Define timezones\n",
        "        gmt = pytz.timezone('GMT')\n",
        "        est = pytz.timezone('US/Eastern')\n",
        "\n",
        "        # Convert the 'datetime' column to EST\n",
        "        dataframe['datetime'] = pd.to_datetime(dataframe['datetime'])  # Ensure column is in datetime format\n",
        "        dataframe['datetime'] = dataframe['datetime'].dt.tz_localize(gmt).dt.tz_convert(est).dt.tz_localize(None)\n",
        "\n",
        "        print(\"Datetime column converted to EST.\")\n",
        "        return dataframe\n",
        "    except Exception as e:\n",
        "        print(f\"Error during timezone conversion: {e}\")\n",
        "        return dataframe\n",
        "\n",
        "# Function to update the master file\n",
        "def update_master_file(master_file, temp_file):\n",
        "    try:\n",
        "        # Load the daily data\n",
        "        daily_data = pd.read_csv(temp_file)\n",
        "\n",
        "        # Convert the datetime column to EST\n",
        "        daily_data = convert_to_est(daily_data)\n",
        "\n",
        "        if os.path.exists(master_file):\n",
        "            # Load the master data\n",
        "            master_data = pd.read_csv(master_file)\n",
        "\n",
        "            # Merge data, avoiding duplicates\n",
        "            updated_data = pd.concat([master_data, daily_data]).drop_duplicates()\n",
        "        else:\n",
        "            updated_data = daily_data\n",
        "\n",
        "        # Save the updated data back to the master file\n",
        "        updated_data.to_csv(master_file, index=False)\n",
        "        print(f\"Master file {master_file} updated successfully.\")\n",
        "        print(updated_data.iloc[-1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error updating master file: {e}\")\n",
        "\n",
        "# Download ES DATA\n",
        "download_futures_data(\n",
        "    username='your_username',\n",
        "    password='your_password',\n",
        "    symbol='ES',\n",
        "    exchange='CME_MINI',\n",
        "    interval=Interval.in_2_hour,\n",
        "    n_bars=5000,\n",
        "    filename='temp_es_2h_data.csv'\n",
        ")\n",
        "\n",
        "# Main script logic\n",
        "def main():\n",
        "    print(f\"Script started at {datetime.now()}\")\n",
        "\n",
        "    # Check if the local daily data file exists\n",
        "    if os.path.exists(TWOH_TEMP_FILE):\n",
        "        # Update the master file\n",
        "        update_master_file(TWOH_MASTER_FILE, TWOH_TEMP_FILE)\n",
        "\n",
        "        # Remove the temporary file\n",
        "        try:\n",
        "            os.remove(TWOH_TEMP_FILE)\n",
        "            print(f\"Temporary file {TWOH_TEMP_FILE} removed.\")\n",
        "        except OSError as e:\n",
        "            print(f\"Error removing temporary file: {e}\")\n",
        "    else:\n",
        "        print(f\"Daily data file {TWOH_TEMP_FILE} not found. Please ensure it exists.\")\n",
        "\n",
        "    print(f\"Script completed at {datetime.now()}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXHs90X8uHD1",
        "outputId": "ad144a91-94ef-449c-a8dd-c111b4a27acc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tvDatafeed.main:error while signin\n",
            "WARNING:tvDatafeed.main:you are using nologin method, data you access may be limited\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data for ES saved to temp_es_15m_data.csv\n",
            "Script started at 2025-09-07 04:20:04.118024\n",
            "Datetime column converted to EST.\n",
            "Master file /content/drive/My Drive/Data/ES Price Data/ES_15M_Price_Data.csv updated successfully.\n",
            "\n",
            "datetime    2025-09-05 16:45:00\n",
            "symbol            CME_MINI:ES1!\n",
            "open                     6487.0\n",
            "high                    6489.25\n",
            "low                      6486.5\n",
            "close                   6488.75\n",
            "volume                   4081.0\n",
            "Name: 4999, dtype: object\n",
            "Temporary file temp_es_15m_data.csv removed.\n",
            "Script completed at 2025-09-07 04:20:05.785122\n"
          ]
        }
      ],
      "source": [
        "### ES 15M TIMEFRAME ###\n",
        "\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import pytz  # Required for timezone conversion\n",
        "\n",
        "# Configuration\n",
        "FIFTEENM_TEMP_FILE = \"temp_es_15m_data.csv\"  # Name of the local file containing daily data\n",
        "FIFTEENM_MASTER_FILE = \"/content/drive/My Drive/Data/ES Price Data/ES_15M_Price_Data.csv\"  # Path to the master file in Google Drive\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Function to download temp file from TradingView\n",
        "def download_futures_data(username: str, password: str, symbol: str, exchange: str, interval: Interval, n_bars: int,\n",
        "                          filename: str):\n",
        "    # Initialize the TvDatafeed object with the given username and password\n",
        "    tv = TvDatafeed(username, password)\n",
        "\n",
        "    # Get the historical data for the specified futures contract\n",
        "    futures_data = tv.get_hist(symbol=symbol, exchange=exchange, interval=interval, n_bars=n_bars, fut_contract=1)\n",
        "\n",
        "    # Save the data to a CSV file\n",
        "    futures_data.to_csv(filename)\n",
        "    print(f\"Data for {symbol} saved to {filename}\")\n",
        "\n",
        "# Function to convert datetime to New York EST\n",
        "def convert_to_est(dataframe):\n",
        "    try:\n",
        "        # Define timezones\n",
        "        gmt = pytz.timezone('GMT')\n",
        "        est = pytz.timezone('US/Eastern')\n",
        "\n",
        "        # Convert the 'datetime' column to EST\n",
        "        dataframe['datetime'] = pd.to_datetime(dataframe['datetime'])  # Ensure column is in datetime format\n",
        "        dataframe['datetime'] = dataframe['datetime'].dt.tz_localize(gmt).dt.tz_convert(est).dt.tz_localize(None)\n",
        "\n",
        "        print(\"Datetime column converted to EST.\")\n",
        "        return dataframe\n",
        "    except Exception as e:\n",
        "        print(f\"Error during timezone conversion: {e}\")\n",
        "        return dataframe\n",
        "\n",
        "# Function to update the master file\n",
        "def update_master_file(master_file, temp_file):\n",
        "    try:\n",
        "        # Load the daily data\n",
        "        daily_data = pd.read_csv(temp_file)\n",
        "\n",
        "        # Convert the datetime column to EST\n",
        "        daily_data = convert_to_est(daily_data)\n",
        "\n",
        "        if os.path.exists(master_file):\n",
        "            # Load the master data\n",
        "            master_data = pd.read_csv(master_file)\n",
        "\n",
        "            # Merge data, avoiding duplicates\n",
        "            updated_data = pd.concat([master_data, daily_data]).drop_duplicates()\n",
        "        else:\n",
        "            updated_data = daily_data\n",
        "\n",
        "        # Save the updated data back to the master file\n",
        "        updated_data.to_csv(master_file, index=False)\n",
        "        print(f\"Master file {master_file} updated successfully.\\n\")\n",
        "        print(updated_data.iloc[-1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error updating master file: {e}\")\n",
        "\n",
        "# Download ES DATA\n",
        "download_futures_data(\n",
        "    username='your_username',\n",
        "    password='your_password',\n",
        "    symbol='ES',\n",
        "    exchange='CME_MINI',\n",
        "    interval=Interval.in_15_minute,\n",
        "    n_bars=5000,\n",
        "    filename='temp_es_15m_data.csv'\n",
        ")\n",
        "\n",
        "# Main script logic\n",
        "def main():\n",
        "    print(f\"Script started at {datetime.now()}\")\n",
        "\n",
        "    # Check if the local daily data file exists\n",
        "    if os.path.exists(FIFTEENM_TEMP_FILE):\n",
        "        # Update the master file\n",
        "        update_master_file(FIFTEENM_MASTER_FILE, FIFTEENM_TEMP_FILE)\n",
        "\n",
        "        # Remove the temporary file\n",
        "        try:\n",
        "            os.remove(FIFTEENM_TEMP_FILE)\n",
        "            print(f\"Temporary file {FIFTEENM_TEMP_FILE} removed.\")\n",
        "        except OSError as e:\n",
        "            print(f\"Error removing temporary file: {e}\")\n",
        "    else:\n",
        "        print(f\"Daily data file {FIFTEENM_TEMP_FILE} not found. Please ensure it exists.\")\n",
        "\n",
        "    print(f\"Script completed at {datetime.now()}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "M3_BR278xnfw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba1d50cd-b325-457f-f203-8981f57ce690"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tvDatafeed.main:error while signin\n",
            "WARNING:tvDatafeed.main:you are using nologin method, data you access may be limited\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data for NQ saved to temp_nq_2h_data.csv\n",
            "Script started at 2025-09-07 04:20:07.837861\n",
            "Datetime column converted to EST.\n",
            "Master file /content/drive/My Drive/Data/NQ Price Data/NQ_2H_Price_Data.csv updated successfully.\n",
            "\n",
            "datetime    2025-09-05 16:00:00\n",
            "symbol            CME_MINI:NQ1!\n",
            "open                   23691.25\n",
            "high                   23696.25\n",
            "low                    23666.75\n",
            "close                  23673.25\n",
            "volume                  13811.0\n",
            "Name: 4999, dtype: object\n",
            "Temporary file temp_nq_2h_data.csv removed.\n",
            "Script completed at 2025-09-07 04:20:08.879572\n"
          ]
        }
      ],
      "source": [
        "### NQ 2H TIMEFRAME ###\n",
        "\n",
        "\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import pytz  # Required for timezone conversion\n",
        "\n",
        "# Configuration\n",
        "TWOH_TEMP_FILE = \"temp_nq_2h_data.csv\"  # Name of the local file containing daily data\n",
        "TWOH_MASTER_FILE = \"/content/drive/My Drive/Data/NQ Price Data/NQ_2H_Price_Data.csv\"  # Path to the master file in Google Drive\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Function to download temp file from TradingView\n",
        "def download_futures_data(username: str, password: str, symbol: str, exchange: str, interval: Interval, n_bars: int,\n",
        "                          filename: str):\n",
        "    # Initialize the TvDatafeed object with the given username and password\n",
        "    tv = TvDatafeed(username, password)\n",
        "\n",
        "    # Get the historical data for the specified futures contract\n",
        "    futures_data = tv.get_hist(symbol=symbol, exchange=exchange, interval=interval, n_bars=n_bars, fut_contract=1)\n",
        "\n",
        "    # Save the data to a CSV file\n",
        "    futures_data.to_csv(filename)\n",
        "    print(f\"Data for {symbol} saved to {filename}\")\n",
        "\n",
        "# Function to convert datetime to New York EST\n",
        "def convert_to_est(dataframe):\n",
        "    try:\n",
        "        # Define timezones\n",
        "        gmt = pytz.timezone('GMT')\n",
        "        est = pytz.timezone('US/Eastern')\n",
        "\n",
        "        # Convert the 'datetime' column to EST\n",
        "        dataframe['datetime'] = pd.to_datetime(dataframe['datetime'])  # Ensure column is in datetime format\n",
        "        dataframe['datetime'] = dataframe['datetime'].dt.tz_localize(gmt).dt.tz_convert(est).dt.tz_localize(None)\n",
        "\n",
        "        print(\"Datetime column converted to EST.\")\n",
        "        return dataframe\n",
        "    except Exception as e:\n",
        "        print(f\"Error during timezone conversion: {e}\")\n",
        "        return dataframe\n",
        "\n",
        "# Function to update the master file\n",
        "def update_master_file(master_file, temp_file):\n",
        "    try:\n",
        "        # Load the daily data\n",
        "        daily_data = pd.read_csv(temp_file)\n",
        "\n",
        "        # Convert the datetime column to EST\n",
        "        daily_data = convert_to_est(daily_data)\n",
        "\n",
        "        if os.path.exists(master_file):\n",
        "            # Load the master data\n",
        "            master_data = pd.read_csv(master_file)\n",
        "\n",
        "            # Merge data, avoiding duplicates\n",
        "            updated_data = pd.concat([master_data, daily_data]).drop_duplicates()\n",
        "        else:\n",
        "            updated_data = daily_data\n",
        "\n",
        "        # Save the updated data back to the master file\n",
        "        updated_data.to_csv(master_file, index=False)\n",
        "        print(f\"Master file {master_file} updated successfully.\\n\")\n",
        "        print(updated_data.iloc[-1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error updating master file: {e}\")\n",
        "\n",
        "# Download NQ DATA\n",
        "download_futures_data(\n",
        "    username='your_username',\n",
        "    password='your_password',\n",
        "    symbol='NQ',\n",
        "    exchange='CME_MINI',\n",
        "    interval=Interval.in_2_hour,\n",
        "    n_bars=5000,\n",
        "    filename='temp_nq_2h_data.csv'\n",
        ")\n",
        "\n",
        "# Main script logic\n",
        "def main():\n",
        "    print(f\"Script started at {datetime.now()}\")\n",
        "\n",
        "    # Check if the local daily data file exists\n",
        "    if os.path.exists(TWOH_TEMP_FILE):\n",
        "        # Update the master file\n",
        "        update_master_file(TWOH_MASTER_FILE, TWOH_TEMP_FILE)\n",
        "\n",
        "        # Remove the temporary file\n",
        "        try:\n",
        "            os.remove(TWOH_TEMP_FILE)\n",
        "            print(f\"Temporary file {TWOH_TEMP_FILE} removed.\")\n",
        "        except OSError as e:\n",
        "            print(f\"Error removing temporary file: {e}\")\n",
        "    else:\n",
        "        print(f\"Daily data file {TWOH_TEMP_FILE} not found. Please ensure it exists.\")\n",
        "\n",
        "    print(f\"Script completed at {datetime.now()}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHoKQT4_ymwo",
        "outputId": "b2dcb26e-42e7-4bac-b9ea-861f9b66c8e8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tvDatafeed.main:error while signin\n",
            "WARNING:tvDatafeed.main:you are using nologin method, data you access may be limited\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data for NQ saved to temp_nq_15m_data.csv\n",
            "Script started at 2025-09-07 04:20:11.147050\n",
            "Datetime column converted to EST.\n",
            "Master file /content/drive/My Drive/Data/NQ Price Data/NQ_15M_Price_Data.csv updated successfully.\n",
            "\n",
            "datetime    2025-09-05 16:45:00\n",
            "symbol            CME_MINI:NQ1!\n",
            "open                    23670.5\n",
            "high                    23677.0\n",
            "low                     23669.0\n",
            "close                  23673.25\n",
            "volume                   1255.0\n",
            "Name: 4999, dtype: object\n",
            "Temporary file temp_nq_15m_data.csv removed.\n",
            "Script completed at 2025-09-07 04:20:12.311838\n"
          ]
        }
      ],
      "source": [
        "### NQ 15M TIMEFRAME ###\n",
        "\n",
        "\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import pytz  # Required for timezone conversion\n",
        "\n",
        "# Configuration\n",
        "FIFTEENM_TEMP_FILE = \"temp_nq_15m_data.csv\"  # Name of the local file containing daily data\n",
        "FIFTEENM_MASTER_FILE = \"/content/drive/My Drive/Data/NQ Price Data/NQ_15M_Price_Data.csv\"  # Path to the master file in Google Drive\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Function to download temp file from TradingView\n",
        "def download_futures_data(username: str, password: str, symbol: str, exchange: str, interval: Interval, n_bars: int,\n",
        "                          filename: str):\n",
        "    # Initialize the TvDatafeed object with the given username and password\n",
        "    tv = TvDatafeed(username, password)\n",
        "\n",
        "    # Get the historical data for the specified futures contract\n",
        "    futures_data = tv.get_hist(symbol=symbol, exchange=exchange, interval=interval, n_bars=n_bars, fut_contract=1)\n",
        "\n",
        "    # Save the data to a CSV file\n",
        "    futures_data.to_csv(filename)\n",
        "    print(f\"Data for {symbol} saved to {filename}\")\n",
        "\n",
        "# Function to convert datetime to New York EST\n",
        "def convert_to_est(dataframe):\n",
        "    try:\n",
        "        # Define timezones\n",
        "        gmt = pytz.timezone('GMT')\n",
        "        est = pytz.timezone('US/Eastern')\n",
        "\n",
        "        # Convert the 'datetime' column to EST\n",
        "        dataframe['datetime'] = pd.to_datetime(dataframe['datetime'])  # Ensure column is in datetime format\n",
        "        dataframe['datetime'] = dataframe['datetime'].dt.tz_localize(gmt).dt.tz_convert(est).dt.tz_localize(None)\n",
        "\n",
        "        print(\"Datetime column converted to EST.\")\n",
        "        return dataframe\n",
        "    except Exception as e:\n",
        "        print(f\"Error during timezone conversion: {e}\")\n",
        "        return dataframe\n",
        "\n",
        "# Function to update the master file\n",
        "def update_master_file(master_file, temp_file):\n",
        "    try:\n",
        "        # Load the daily data\n",
        "        daily_data = pd.read_csv(temp_file)\n",
        "\n",
        "        # Convert the datetime column to EST\n",
        "        daily_data = convert_to_est(daily_data)\n",
        "\n",
        "        if os.path.exists(master_file):\n",
        "            # Load the master data\n",
        "            master_data = pd.read_csv(master_file)\n",
        "\n",
        "            # Merge data, avoiding duplicates\n",
        "            updated_data = pd.concat([master_data, daily_data]).drop_duplicates()\n",
        "        else:\n",
        "            updated_data = daily_data\n",
        "\n",
        "        # Save the updated data back to the master file\n",
        "        updated_data.to_csv(master_file, index=False)\n",
        "        print(f\"Master file {master_file} updated successfully.\\n\")\n",
        "        print(updated_data.iloc[-1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error updating master file: {e}\")\n",
        "\n",
        "# Download NQ DATA\n",
        "download_futures_data(\n",
        "    username='your_username',\n",
        "    password='your_password',\n",
        "    symbol='NQ',\n",
        "    exchange='CME_MINI',\n",
        "    interval=Interval.in_15_minute,\n",
        "    n_bars=5000,\n",
        "    filename='temp_nq_15m_data.csv'\n",
        ")\n",
        "\n",
        "# Main script logic\n",
        "def main():\n",
        "    print(f\"Script started at {datetime.now()}\")\n",
        "\n",
        "    # Check if the local daily data file exists\n",
        "    if os.path.exists(FIFTEENM_TEMP_FILE):\n",
        "        # Update the master file\n",
        "        update_master_file(FIFTEENM_MASTER_FILE, FIFTEENM_TEMP_FILE)\n",
        "\n",
        "        # Remove the temporary file\n",
        "        try:\n",
        "            os.remove(FIFTEENM_TEMP_FILE)\n",
        "            print(f\"Temporary file {FIFTEENM_TEMP_FILE} removed.\")\n",
        "        except OSError as e:\n",
        "            print(f\"Error removing temporary file: {e}\")\n",
        "    else:\n",
        "        print(f\"Daily data file {FIFTEENM_TEMP_FILE} not found. Please ensure it exists.\")\n",
        "\n",
        "    print(f\"Script completed at {datetime.now()}\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F0foJ7dJ0DYH",
        "outputId": "740eee1f-1a77-4df2-86f1-0b40c9e7a4de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tvDatafeed.main:error while signin\n",
            "WARNING:tvDatafeed.main:you are using nologin method, data you access may be limited\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data for NQ saved to temp_nq_5m_data.csv\n",
            "Script started at 2025-09-07 04:20:14.375480\n",
            "Datetime column converted to EST.\n",
            "Master file /content/drive/My Drive/Data/NQ Price Data/NQ_5M_Price_Data.csv updated successfully.\n",
            "\n",
            "datetime    2025-09-05 16:55:00\n",
            "symbol            CME_MINI:NQ1!\n",
            "open                    23673.5\n",
            "high                    23676.0\n",
            "low                    23672.25\n",
            "close                  23673.25\n",
            "volume                    567.0\n",
            "Name: 4999, dtype: object\n",
            "Temporary file temp_nq_5m_data.csv removed.\n",
            "Script completed at 2025-09-07 04:20:16.122733\n"
          ]
        }
      ],
      "source": [
        "### NQ 5M TIMEFRAME ###\n",
        "\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import pytz  # Required for timezone conversion\n",
        "\n",
        "# # Configuration\n",
        "FIVEM_TEMP_FILE = \"temp_nq_5m_data.csv\"  # Name of the local file containing daily data\n",
        "FIVEM_MASTER_FILE = \"/content/drive/My Drive/Data/NQ Price Data/NQ_5M_Price_Data.csv\"  # Path to the master file in Google Drive\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Function to download temp file from TradingView\n",
        "def download_futures_data(username: str, password: str, symbol: str, exchange: str, interval: Interval, n_bars: int,\n",
        "                          filename: str):\n",
        "    # Initialize the TvDatafeed object with the given username and password\n",
        "    tv = TvDatafeed(username, password)\n",
        "\n",
        "    # Get the historical data for the specified futures contract\n",
        "    futures_data = tv.get_hist(symbol=symbol, exchange=exchange, interval=interval, n_bars=n_bars, fut_contract=1)\n",
        "\n",
        "    # Save the data to a CSV file\n",
        "    futures_data.to_csv(filename)\n",
        "    print(f\"Data for {symbol} saved to {filename}\")\n",
        "\n",
        "# Function to convert datetime to New York EST\n",
        "def convert_to_est(dataframe):\n",
        "    try:\n",
        "        # Define timezones\n",
        "        gmt = pytz.timezone('GMT')\n",
        "        est = pytz.timezone('US/Eastern')\n",
        "\n",
        "        # Convert the 'datetime' column to EST\n",
        "        dataframe['datetime'] = pd.to_datetime(dataframe['datetime'])  # Ensure column is in datetime format\n",
        "        dataframe['datetime'] = dataframe['datetime'].dt.tz_localize(gmt).dt.tz_convert(est).dt.tz_localize(None)\n",
        "\n",
        "        print(\"Datetime column converted to EST.\")\n",
        "        return dataframe\n",
        "    except Exception as e:\n",
        "        print(f\"Error during timezone conversion: {e}\")\n",
        "        return dataframe\n",
        "\n",
        "# Function to update the master file\n",
        "def update_master_file(master_file, temp_file):\n",
        "    try:\n",
        "        # Load the daily data\n",
        "        daily_data = pd.read_csv(temp_file)\n",
        "\n",
        "        # Convert the datetime column to EST\n",
        "        daily_data = convert_to_est(daily_data)\n",
        "\n",
        "        if os.path.exists(master_file):\n",
        "            # Load the master data\n",
        "            master_data = pd.read_csv(master_file)\n",
        "\n",
        "            # Merge data, avoiding duplicates\n",
        "            updated_data = pd.concat([master_data, daily_data]).drop_duplicates()\n",
        "        else:\n",
        "            updated_data = daily_data\n",
        "\n",
        "        # Save the updated data back to the master file\n",
        "        updated_data.to_csv(master_file, index=False)\n",
        "        print(f\"Master file {master_file} updated successfully.\\n\")\n",
        "        print(updated_data.iloc[-1])\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error updating master file: {e}\")\n",
        "\n",
        "# Download NQ DATA\n",
        "download_futures_data(\n",
        "    username='your_username',\n",
        "    password='your_password',\n",
        "    symbol='NQ',\n",
        "    exchange='CME_MINI',\n",
        "    interval=Interval.in_5_minute,\n",
        "    n_bars=5000,\n",
        "    filename='temp_nq_5m_data.csv'\n",
        ")\n",
        "\n",
        "# Main script logic\n",
        "def main():\n",
        "    print(f\"Script started at {datetime.now()}\")\n",
        "\n",
        "    # Check if the local daily data file exists\n",
        "    if os.path.exists(FIVEM_TEMP_FILE):\n",
        "        # Update the master file\n",
        "        update_master_file(FIVEM_MASTER_FILE, FIVEM_TEMP_FILE)\n",
        "\n",
        "        # Remove the temporary file\n",
        "        try:\n",
        "            os.remove(FIVEM_TEMP_FILE)\n",
        "            print(f\"Temporary file {FIVEM_TEMP_FILE} removed.\")\n",
        "        except OSError as e:\n",
        "            print(f\"Error removing temporary file: {e}\")\n",
        "    else:\n",
        "        print(f\"Daily data file {FIVEM_TEMP_FILE} not found. Please ensure it exists.\")\n",
        "\n",
        "    print(f\"Script completed at {datetime.now()}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6876wEw1UT2",
        "outputId": "91ebad86-d3ff-4d18-c9e3-949d2890f0a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tvDatafeed.main:error while signin\n",
            "WARNING:tvDatafeed.main:you are using nologin method, data you access may be limited\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data for GC saved to temp_gc_2h_data.csv\n",
            "Script started at 2025-09-07 04:20:19.909284\n",
            "Datetime column converted to EST.\n",
            "Master file /content/drive/My Drive/Data/GC Price Data/GC_2H_Price_Data.csv updated successfully.\n",
            "\n",
            "datetime    2025-09-05 16:00:00\n",
            "symbol               COMEX:GC1!\n",
            "open                     3646.4\n",
            "high                     3647.4\n",
            "low                      3639.0\n",
            "close                    3639.8\n",
            "volume                   5158.0\n",
            "Name: 4999, dtype: object\n",
            "Temporary file temp_gc_2h_data.csv removed.\n",
            "Script completed at 2025-09-07 04:20:20.557607\n"
          ]
        }
      ],
      "source": [
        "### GC 2H TIMEFRAME ###\n",
        "\n",
        "from tvDatafeed import TvDatafeed, Interval\n",
        "import os\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "import pytz  # Required for timezone conversion\n",
        "\n",
        "# Configuration\n",
        "TWOH_TEMP_FILE = \"temp_gc_2h_data.csv\"  # Name of the local file containing daily data\n",
        "TWOH_MASTER_FILE = \"/content/drive/My Drive/Data/GC Price Data/GC_2H_Price_Data.csv\"  # Path to the master file in Google Drive\n",
        "\n",
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Function to download temp file from TradingView\n",
        "def download_futures_data(username: str, password: str, symbol: str, exchange: str, interval: Interval, n_bars: int,\n",
        "                          filename: str):\n",
        "    # Initialize the TvDatafeed object with the given username and password\n",
        "    tv = TvDatafeed(username, password)\n",
        "\n",
        "    # Get the historical data for the specified futures contract\n",
        "    futures_data = tv.get_hist(symbol=symbol, exchange=exchange, interval=interval, n_bars=n_bars, fut_contract=1)\n",
        "\n",
        "    # Save the data to a CSV file\n",
        "    futures_data.to_csv(filename)\n",
        "    print(f\"Data for {symbol} saved to {filename}\")\n",
        "\n",
        "# Function to convert datetime to New York EST\n",
        "def convert_to_est(dataframe):\n",
        "    try:\n",
        "        # Define timezones\n",
        "        gmt = pytz.timezone('GMT')\n",
        "        est = pytz.timezone('US/Eastern')\n",
        "\n",
        "        # Convert the 'datetime' column to EST\n",
        "        dataframe['datetime'] = pd.to_datetime(dataframe['datetime'])  # Ensure column is in datetime format\n",
        "        dataframe['datetime'] = dataframe['datetime'].dt.tz_localize(gmt).dt.tz_convert(est).dt.tz_localize(None)\n",
        "\n",
        "        print(\"Datetime column converted to EST.\")\n",
        "        return dataframe\n",
        "    except Exception as e:\n",
        "        print(f\"Error during timezone conversion: {e}\")\n",
        "        return dataframe\n",
        "\n",
        "# Function to update the master file\n",
        "def update_master_file(master_file, temp_file):\n",
        "    try:\n",
        "        # Load the daily data\n",
        "        daily_data = pd.read_csv(temp_file)\n",
        "\n",
        "        # Convert the datetime column to EST\n",
        "        daily_data = convert_to_est(daily_data)\n",
        "\n",
        "        if os.path.exists(master_file):\n",
        "            # Load the master data\n",
        "            master_data = pd.read_csv(master_file)\n",
        "\n",
        "            # Merge data, avoiding duplicates\n",
        "            updated_data = pd.concat([master_data, daily_data]).drop_duplicates()\n",
        "        else:\n",
        "            updated_data = daily_data\n",
        "\n",
        "        # Save the updated data back to the master file\n",
        "        updated_data.to_csv(master_file, index=False)\n",
        "        print(f\"Master file {master_file} updated successfully.\\n\")\n",
        "        print(updated_data.iloc[-1])\n",
        "    except Exception as e:\n",
        "        print(f\"Error updating master file: {e}\")\n",
        "\n",
        "# GC FORECAST\n",
        "download_futures_data(\n",
        "    username='your_username',\n",
        "    password='your_password',\n",
        "    symbol='GC',\n",
        "    exchange='COMEX',\n",
        "    interval=Interval.in_2_hour,\n",
        "    n_bars=5000,\n",
        "    filename='temp_gc_2h_data.csv'\n",
        ")\n",
        "\n",
        "# Main script logic\n",
        "def main():\n",
        "    print(f\"Script started at {datetime.now()}\")\n",
        "\n",
        "    # Check if the local daily data file exists\n",
        "    if os.path.exists(TWOH_TEMP_FILE):\n",
        "        # Update the master file\n",
        "        update_master_file(TWOH_MASTER_FILE, TWOH_TEMP_FILE)\n",
        "\n",
        "        # Remove the temporary file\n",
        "        try:\n",
        "            os.remove(TWOH_TEMP_FILE)\n",
        "            print(f\"Temporary file {TWOH_TEMP_FILE} removed.\")\n",
        "        except OSError as e:\n",
        "            print(f\"Error removing temporary file: {e}\")\n",
        "    else:\n",
        "        print(f\"Daily data file {TWOH_TEMP_FILE} not found. Please ensure it exists.\")\n",
        "\n",
        "    print(f\"Script completed at {datetime.now()}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNL2ElOmT+5fCHQNiUY4lv/",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}